{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "### 1. Will a fellow get placed or not\n",
    "### 2. How long will it take to get placed if placed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Fellow will get placed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_Pathrise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pathrise_status</th>\n",
       "      <th>primary_track</th>\n",
       "      <th>cohort_tag</th>\n",
       "      <th>program_duration_days</th>\n",
       "      <th>placed</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>highest_level_of_education</th>\n",
       "      <th>length_of_job_search</th>\n",
       "      <th>biggest_challenge_in_search</th>\n",
       "      <th>professional_experience</th>\n",
       "      <th>work_authorization_status</th>\n",
       "      <th>number_of_interviews</th>\n",
       "      <th>number_of_applications</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Active</td>\n",
       "      <td>SWE</td>\n",
       "      <td>OCT19A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>3-5 months</td>\n",
       "      <td>Hearing back on my applications</td>\n",
       "      <td>3-4 years</td>\n",
       "      <td>Canada Citizen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic White or Euro-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Active</td>\n",
       "      <td>PSO</td>\n",
       "      <td>JAN20A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Some College, No Degree</td>\n",
       "      <td>3-5 months</td>\n",
       "      <td>Getting past final round interviews</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic White or Euro-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>Design</td>\n",
       "      <td>AUG19B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Employed Part-Time</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Less than one month</td>\n",
       "      <td>Figuring out which jobs to apply for</td>\n",
       "      <td>Less than one year</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian or Asian American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>PSO</td>\n",
       "      <td>AUG19B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Less than one month</td>\n",
       "      <td>Getting past final round interviews</td>\n",
       "      <td>Less than one year</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>Decline to Self Identify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Placed</td>\n",
       "      <td>SWE</td>\n",
       "      <td>AUG19A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>1-2 months</td>\n",
       "      <td>Hearing back on my applications</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>F1 Visa/OPT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id pathrise_status primary_track cohort_tag  program_duration_days  placed  \\\n",
       "0   1          Active           SWE     OCT19A                    NaN       0   \n",
       "1   2          Active           PSO     JAN20A                    NaN       0   \n",
       "2   3     Closed Lost        Design     AUG19B                    0.0       0   \n",
       "3   4     Closed Lost           PSO     AUG19B                    0.0       0   \n",
       "4   5          Placed           SWE     AUG19A                   89.0       1   \n",
       "\n",
       "   employment_status  highest_level_of_education length_of_job_search  \\\n",
       "0          Unemployed          Bachelor's Degree           3-5 months   \n",
       "1          Unemployed    Some College, No Degree           3-5 months   \n",
       "2  Employed Part-Time            Master's Degree  Less than one month   \n",
       "3          Contractor          Bachelor's Degree  Less than one month   \n",
       "4          Unemployed          Bachelor's Degree           1-2 months   \n",
       "\n",
       "            biggest_challenge_in_search professional_experience  \\\n",
       "0       Hearing back on my applications               3-4 years   \n",
       "1   Getting past final round interviews               1-2 years   \n",
       "2  Figuring out which jobs to apply for      Less than one year   \n",
       "3   Getting past final round interviews      Less than one year   \n",
       "4       Hearing back on my applications               1-2 years   \n",
       "\n",
       "  work_authorization_status  number_of_interviews  number_of_applications  \\\n",
       "0            Canada Citizen                   2.0                     900   \n",
       "1                   Citizen                   6.0                       0   \n",
       "2                   Citizen                   0.0                       0   \n",
       "3                   Citizen                   5.0                      25   \n",
       "4               F1 Visa/OPT                  10.0                     100   \n",
       "\n",
       "  gender                                 race  \n",
       "0   Male  Non-Hispanic White or Euro-American  \n",
       "1   Male  Non-Hispanic White or Euro-American  \n",
       "2   Male         East Asian or Asian American  \n",
       "3   Male             Decline to Self Identify  \n",
       "4   Male         East Asian or Asian American  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'pathrise_status',\n",
       " 'primary_track',\n",
       " 'cohort_tag',\n",
       " 'program_duration_days',\n",
       " 'placed',\n",
       " 'employment_status ',\n",
       " 'highest_level_of_education',\n",
       " 'length_of_job_search',\n",
       " 'biggest_challenge_in_search',\n",
       " 'professional_experience',\n",
       " 'work_authorization_status',\n",
       " 'number_of_interviews',\n",
       " 'number_of_applications',\n",
       " 'gender',\n",
       " 'race']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headings_list = list(data.columns)\n",
    "headings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pathrise_status</th>\n",
       "      <th>primary_track</th>\n",
       "      <th>cohort_tag</th>\n",
       "      <th>program_duration_days</th>\n",
       "      <th>placed</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>highest_level_of_education</th>\n",
       "      <th>length_of_job_search</th>\n",
       "      <th>biggest_challenge_in_search</th>\n",
       "      <th>professional_experience</th>\n",
       "      <th>work_authorization_status</th>\n",
       "      <th>number_of_interviews</th>\n",
       "      <th>number_of_applications</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, pathrise_status, primary_track, cohort_tag, program_duration_days, placed, employment_status , highest_level_of_education, length_of_job_search, biggest_challenge_in_search, professional_experience, work_authorization_status, number_of_interviews, number_of_applications, gender, race]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking whether all ids are unique\n",
    "data[data['id'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting features with text to numbers so that it can be fed to an ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_list_for_num_process = headings_list[:]\n",
    "headings_list_for_num_process.remove('id')\n",
    "headings_list_for_num_process.remove('placed')\n",
    "headings_list_for_num_process.remove('program_duration_days')\n",
    "headings_list_for_num_process.remove('number_of_interviews')\n",
    "headings_list_for_num_process.remove('number_of_applications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pathrise_status',\n",
       " 'primary_track',\n",
       " 'cohort_tag',\n",
       " 'employment_status ',\n",
       " 'highest_level_of_education',\n",
       " 'length_of_job_search',\n",
       " 'biggest_challenge_in_search',\n",
       " 'professional_experience',\n",
       " 'work_authorization_status',\n",
       " 'gender',\n",
       " 'race']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below are the features that are going to be converted to multiple columns \n",
    "# with numeric values based on the text information provided.Although cohort_tag \n",
    "# might not be an important feature, I'm including it now.\n",
    "headings_list_for_num_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating unique columns dictionary\n",
    "new_dataframe_dict = {}\n",
    "all_uniques_encoded = {}\n",
    "for i in headings_list_for_num_process:\n",
    "    codes, uniques = pd.factorize(data[i])\n",
    "    new_dataframe_dict[i] = codes\n",
    "    all_uniques_encoded[i] = uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pathrise_status': Index(['Active', 'Closed Lost', 'Placed', 'Withdrawn (Failed)',\n",
       "        'Withdrawn (Trial)', 'Withdrawn', 'Deferred', 'Break', 'MIA'],\n",
       "       dtype='object'),\n",
       " 'primary_track': Index(['SWE', 'PSO', 'Design', 'Data', 'Web', 'Marketing'], dtype='object'),\n",
       " 'cohort_tag': Index(['OCT19A', 'JAN20A', 'AUG19B', 'AUG19A', 'SEP19A', 'AUG19C', 'DEC19A',\n",
       "        'FEB20A', 'NOV19A', 'NOV19B', 'JAN20B', 'FEB20B', 'JUL19B', 'APR20A',\n",
       "        'OCT18A', 'SEP18C', 'OCT18B', 'JAN19A', 'MAR19A', 'FEB19A', 'FEB19B',\n",
       "        'APR19A', 'AUG18A', 'DEC18A', 'MAR19B', 'JAN19B', 'JUN19B', 'SEP18B',\n",
       "        'NOV18A', 'SEP18A', 'APR19B', 'MAY19A', 'JUL19A', 'JUN19A', 'FEB18A',\n",
       "        'JUN18A', 'MAR18A', 'APR18A', 'APR18B', 'MAY18A', 'OCT21A', 'SEP19B',\n",
       "        'MAR20A', 'MAY19B', 'FEB20a', 'OCT19B', 'JAN18A'],\n",
       "       dtype='object'),\n",
       " 'employment_status ': Index(['Unemployed', 'Employed Part-Time', 'Contractor', 'Employed Full-Time',\n",
       "        'Student'],\n",
       "       dtype='object'),\n",
       " 'highest_level_of_education': Index(['Bachelor's Degree', 'Some College, No Degree', 'Master's Degree',\n",
       "        'Doctorate or Professional Degree', 'High School Graduate',\n",
       "        'GED or equivalent', 'Some High School'],\n",
       "       dtype='object'),\n",
       " 'length_of_job_search': Index(['3-5 months', 'Less than one month', '1-2 months', '6 months to a year',\n",
       "        'Over a year'],\n",
       "       dtype='object'),\n",
       " 'biggest_challenge_in_search': Index(['Hearing back on my applications',\n",
       "        'Getting past final round interviews',\n",
       "        'Figuring out which jobs to apply for', 'Technical interviewing',\n",
       "        'Getting past phone screens', 'Lack of relevant experience',\n",
       "        'Technical skills', 'Getting past mid-stage interviews',\n",
       "        'Behavioral interviewing', 'Resume gap'],\n",
       "       dtype='object'),\n",
       " 'professional_experience': Index(['3-4 years', '1-2 years', 'Less than one year', '5+ years'], dtype='object'),\n",
       " 'work_authorization_status': Index(['Canada Citizen', 'Citizen', 'F1 Visa/OPT', 'Green Card', 'F1 Visa/CPT',\n",
       "        'Other', 'STEM OPT', 'Not Authorized', 'H1B'],\n",
       "       dtype='object'),\n",
       " 'gender': Index(['Male', 'Female', 'Decline to Self Identify', 'Non-Binary'], dtype='object'),\n",
       " 'race': Index(['Non-Hispanic White or Euro-American', 'East Asian or Asian American',\n",
       "        'Decline to Self Identify',\n",
       "        'Black, Afro-Caribbean, or African American',\n",
       "        'Latino or Hispanic American', 'Middle Eastern or Arab American',\n",
       "        'South Asian or Indian American', 'Two or More Races',\n",
       "        'Native American or Alaskan Native'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_uniques_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new columns based on the text information\n",
    "df_X = pd.DataFrame()\n",
    "for i in headings_list_for_num_process:\n",
    "    for j in all_uniques_encoded[i]:\n",
    "        df_X[i+'_'+j] = [1 if x == j else 0 for x in data[i]]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2544, 115)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathrise_status_Active</th>\n",
       "      <th>pathrise_status_Closed Lost</th>\n",
       "      <th>pathrise_status_Placed</th>\n",
       "      <th>pathrise_status_Withdrawn (Failed)</th>\n",
       "      <th>pathrise_status_Withdrawn (Trial)</th>\n",
       "      <th>pathrise_status_Withdrawn</th>\n",
       "      <th>pathrise_status_Deferred</th>\n",
       "      <th>pathrise_status_Break</th>\n",
       "      <th>pathrise_status_MIA</th>\n",
       "      <th>primary_track_SWE</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_Non-Binary</th>\n",
       "      <th>race_Non-Hispanic White or Euro-American</th>\n",
       "      <th>race_East Asian or Asian American</th>\n",
       "      <th>race_Decline to Self Identify</th>\n",
       "      <th>race_Black, Afro-Caribbean, or African American</th>\n",
       "      <th>race_Latino or Hispanic American</th>\n",
       "      <th>race_Middle Eastern or Arab American</th>\n",
       "      <th>race_South Asian or Indian American</th>\n",
       "      <th>race_Two or More Races</th>\n",
       "      <th>race_Native American or Alaskan Native</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pathrise_status_Active  pathrise_status_Closed Lost  \\\n",
       "0                       1                            0   \n",
       "1                       1                            0   \n",
       "2                       0                            1   \n",
       "3                       0                            1   \n",
       "4                       0                            0   \n",
       "\n",
       "   pathrise_status_Placed  pathrise_status_Withdrawn (Failed)  \\\n",
       "0                       0                                   0   \n",
       "1                       0                                   0   \n",
       "2                       0                                   0   \n",
       "3                       0                                   0   \n",
       "4                       1                                   0   \n",
       "\n",
       "   pathrise_status_Withdrawn (Trial)  pathrise_status_Withdrawn  \\\n",
       "0                                  0                          0   \n",
       "1                                  0                          0   \n",
       "2                                  0                          0   \n",
       "3                                  0                          0   \n",
       "4                                  0                          0   \n",
       "\n",
       "   pathrise_status_Deferred  pathrise_status_Break  pathrise_status_MIA  \\\n",
       "0                         0                      0                    0   \n",
       "1                         0                      0                    0   \n",
       "2                         0                      0                    0   \n",
       "3                         0                      0                    0   \n",
       "4                         0                      0                    0   \n",
       "\n",
       "   primary_track_SWE  ...  gender_Non-Binary  \\\n",
       "0                  1  ...                  0   \n",
       "1                  0  ...                  0   \n",
       "2                  0  ...                  0   \n",
       "3                  0  ...                  0   \n",
       "4                  1  ...                  0   \n",
       "\n",
       "   race_Non-Hispanic White or Euro-American  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   race_East Asian or Asian American  race_Decline to Self Identify  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  1                              0   \n",
       "3                                  0                              1   \n",
       "4                                  1                              0   \n",
       "\n",
       "   race_Black, Afro-Caribbean, or African American  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   race_Latino or Hispanic American  race_Middle Eastern or Arab American  \\\n",
       "0                                 0                                     0   \n",
       "1                                 0                                     0   \n",
       "2                                 0                                     0   \n",
       "3                                 0                                     0   \n",
       "4                                 0                                     0   \n",
       "\n",
       "   race_South Asian or Indian American  race_Two or More Races  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       0   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "\n",
       "   race_Native American or Alaskan Native  \n",
       "0                                       0  \n",
       "1                                       0  \n",
       "2                                       0  \n",
       "3                                       0  \n",
       "4                                       0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the features that need not be modified for analysis\n",
    "df_X['program_duration_days'] = data['program_duration_days']\n",
    "df_X['number_of_interviews'] = data['number_of_interviews']\n",
    "df_X['number_of_applications'] = data['number_of_applications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathrise_status_Active</th>\n",
       "      <th>pathrise_status_Closed Lost</th>\n",
       "      <th>pathrise_status_Placed</th>\n",
       "      <th>pathrise_status_Withdrawn (Failed)</th>\n",
       "      <th>pathrise_status_Withdrawn (Trial)</th>\n",
       "      <th>pathrise_status_Withdrawn</th>\n",
       "      <th>pathrise_status_Deferred</th>\n",
       "      <th>pathrise_status_Break</th>\n",
       "      <th>pathrise_status_MIA</th>\n",
       "      <th>primary_track_SWE</th>\n",
       "      <th>...</th>\n",
       "      <th>race_Decline to Self Identify</th>\n",
       "      <th>race_Black, Afro-Caribbean, or African American</th>\n",
       "      <th>race_Latino or Hispanic American</th>\n",
       "      <th>race_Middle Eastern or Arab American</th>\n",
       "      <th>race_South Asian or Indian American</th>\n",
       "      <th>race_Two or More Races</th>\n",
       "      <th>race_Native American or Alaskan Native</th>\n",
       "      <th>program_duration_days</th>\n",
       "      <th>number_of_interviews</th>\n",
       "      <th>number_of_applications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pathrise_status_Active  pathrise_status_Closed Lost  \\\n",
       "0                       1                            0   \n",
       "1                       1                            0   \n",
       "2                       0                            1   \n",
       "3                       0                            1   \n",
       "4                       0                            0   \n",
       "\n",
       "   pathrise_status_Placed  pathrise_status_Withdrawn (Failed)  \\\n",
       "0                       0                                   0   \n",
       "1                       0                                   0   \n",
       "2                       0                                   0   \n",
       "3                       0                                   0   \n",
       "4                       1                                   0   \n",
       "\n",
       "   pathrise_status_Withdrawn (Trial)  pathrise_status_Withdrawn  \\\n",
       "0                                  0                          0   \n",
       "1                                  0                          0   \n",
       "2                                  0                          0   \n",
       "3                                  0                          0   \n",
       "4                                  0                          0   \n",
       "\n",
       "   pathrise_status_Deferred  pathrise_status_Break  pathrise_status_MIA  \\\n",
       "0                         0                      0                    0   \n",
       "1                         0                      0                    0   \n",
       "2                         0                      0                    0   \n",
       "3                         0                      0                    0   \n",
       "4                         0                      0                    0   \n",
       "\n",
       "   primary_track_SWE  ...  race_Decline to Self Identify  \\\n",
       "0                  1  ...                              0   \n",
       "1                  0  ...                              0   \n",
       "2                  0  ...                              0   \n",
       "3                  0  ...                              1   \n",
       "4                  1  ...                              0   \n",
       "\n",
       "   race_Black, Afro-Caribbean, or African American  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   race_Latino or Hispanic American  race_Middle Eastern or Arab American  \\\n",
       "0                                 0                                     0   \n",
       "1                                 0                                     0   \n",
       "2                                 0                                     0   \n",
       "3                                 0                                     0   \n",
       "4                                 0                                     0   \n",
       "\n",
       "   race_South Asian or Indian American  race_Two or More Races  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       0   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "\n",
       "   race_Native American or Alaskan Native  program_duration_days  \\\n",
       "0                                       0                    0.0   \n",
       "1                                       0                    0.0   \n",
       "2                                       0                    0.0   \n",
       "3                                       0                    0.0   \n",
       "4                                       0                   89.0   \n",
       "\n",
       "   number_of_interviews  number_of_applications  \n",
       "0                   2.0                     900  \n",
       "1                   6.0                       0  \n",
       "2                   0.0                       0  \n",
       "3                   5.0                      25  \n",
       "4                  10.0                     100  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = data['placed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting pandas dataframe to numpy for sklearn and easier manipulation purposes\n",
    "X = df_X.to_numpy()\n",
    "Y = df_Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2544, 118)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2544,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape =  (2289, 118)\n",
      "X_test_shape =  (255, 118)\n"
     ]
    }
   ],
   "source": [
    "#Splitting data to test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=3)\n",
    "print('X_train_shape = ', X_train.shape)\n",
    "print('X_test_shape = ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_cat shape =  (2289, 2)\n",
      "y_test_cat shape =  (255, 2)\n"
     ]
    }
   ],
   "source": [
    "#Convert to categorical\n",
    "y_train_cat = to_categorical(Y_train)\n",
    "y_test_cat = to_categorical(Y_test)\n",
    "\n",
    "print('y_train_cat shape = ', y_train_cat.shape)\n",
    "print('y_test_cat shape = ', y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_hidden_layer (Dense)   (None, 100)               11900     \n",
      "_________________________________________________________________\n",
      "second_hidden_layer (Dense)  (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "third_hidden_layer (Dense)   (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "forth_hidden_layer (Dense)   (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "fifth_hidden_layer (Dense)   (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 52,502\n",
      "Trainable params: 52,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore some warning logs\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "#  Define a Feed-Forward Model with 2 hidden layers with dimensions 392 and 196 Neurons\n",
    "model_1 = Sequential([\n",
    "  Dense(100, activation='relu', input_shape=(118,), name=\"first_hidden_layer\"),\n",
    "  Dense(100, activation='relu', name=\"second_hidden_layer\"), \n",
    "  Dense(100,activation= 'relu',name = \"third_hidden_layer\"),\n",
    "  Dense(100,activation= 'relu',name = \"forth_hidden_layer\"),\n",
    "  Dense(100,activation= 'relu',name = \"fifth_hidden_layer\"),\n",
    "  Dense(2, activation='softmax'),\n",
    "])\n",
    "\n",
    "#  Validate your Model Architecture\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
      "Epoch 1/250\n",
      "2289/2289 [==============================] - 2s 692us/step - loss: 0.2270 - accuracy: 0.8995 - precision: 0.9538 - recall: 0.8998\n",
      "Epoch 2/250\n",
      "2289/2289 [==============================] - 1s 341us/step - loss: 0.2513 - accuracy: 0.8895 - precision: 0.8956 - recall: 0.9331\n",
      "Epoch 3/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2263 - accuracy: 0.8995 - precision: 0.9446 - recall: 0.9219\n",
      "Epoch 4/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.2656 - accuracy: 0.8917 - precision: 0.9419 - recall: 0.8992\n",
      "Epoch 5/250\n",
      "2289/2289 [==============================] - 1s 364us/step - loss: 0.2547 - accuracy: 0.8807 - precision: 0.9306 - recall: 0.8691\n",
      "Epoch 6/250\n",
      "2289/2289 [==============================] - 1s 364us/step - loss: 0.2556 - accuracy: 0.8716 - precision: 0.9248 - recall: 0.8635\n",
      "Epoch 7/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2823 - accuracy: 0.8602 - precision: 0.8994 - recall: 0.8860\n",
      "Epoch 8/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2724 - accuracy: 0.8598 - precision: 0.9115 - recall: 0.8956\n",
      "Epoch 9/250\n",
      "2289/2289 [==============================] - 1s 339us/step - loss: 0.2417 - accuracy: 0.8724 - precision: 0.9151 - recall: 0.8531\n",
      "Epoch 10/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2478 - accuracy: 0.8803 - precision: 0.9194 - recall: 0.9127\n",
      "Epoch 11/250\n",
      "2289/2289 [==============================] - 1s 387us/step - loss: 0.2477 - accuracy: 0.8794 - precision: 0.9074 - recall: 0.9038\n",
      "Epoch 12/250\n",
      "2289/2289 [==============================] - 1s 352us/step - loss: 0.2432 - accuracy: 0.8751 - precision: 0.9143 - recall: 0.8902\n",
      "Epoch 13/250\n",
      "2289/2289 [==============================] - 1s 349us/step - loss: 0.2922 - accuracy: 0.8567 - precision: 0.9188 - recall: 0.8248\n",
      "Epoch 14/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2578 - accuracy: 0.8781 - precision: 0.9110 - recall: 0.8604\n",
      "Epoch 15/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2415 - accuracy: 0.8947 - precision: 0.9449 - recall: 0.8720\n",
      "Epoch 16/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.2619 - accuracy: 0.8702 - precision: 0.9217 - recall: 0.8494\n",
      "Epoch 17/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2466 - accuracy: 0.8768 - precision: 0.9307 - recall: 0.8410\n",
      "Epoch 18/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2555 - accuracy: 0.8812 - precision: 0.9363 - recall: 0.8700\n",
      "Epoch 19/250\n",
      "2289/2289 [==============================] - 1s 356us/step - loss: 0.2529 - accuracy: 0.8790 - precision: 0.9275 - recall: 0.8761\n",
      "Epoch 20/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2606 - accuracy: 0.8751 - precision: 0.9417 - recall: 0.8771\n",
      "Epoch 21/250\n",
      "2289/2289 [==============================] - 1s 331us/step - loss: 0.2673 - accuracy: 0.8685 - precision: 0.9405 - recall: 0.8525\n",
      "Epoch 22/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2538 - accuracy: 0.8755 - precision: 0.9338 - recall: 0.8177\n",
      "Epoch 23/250\n",
      "2289/2289 [==============================] - 1s 323us/step - loss: 0.2372 - accuracy: 0.8847 - precision: 0.9089 - recall: 0.9004\n",
      "Epoch 24/250\n",
      "2289/2289 [==============================] - 1s 320us/step - loss: 0.2130 - accuracy: 0.9187 - precision: 0.9488 - recall: 0.9162\n",
      "Epoch 25/250\n",
      "2289/2289 [==============================] - 1s 331us/step - loss: 0.2587 - accuracy: 0.8873 - precision: 0.9364 - recall: 0.8792\n",
      "Epoch 26/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2682 - accuracy: 0.8663 - precision: 0.9620 - recall: 0.8182\n",
      "Epoch 27/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2159 - accuracy: 0.9056 - precision: 0.9558 - recall: 0.8811\n",
      "Epoch 28/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.2501 - accuracy: 0.8777 - precision: 0.9546 - recall: 0.8973\n",
      "Epoch 29/250\n",
      "2289/2289 [==============================] - 1s 324us/step - loss: 0.2732 - accuracy: 0.8694 - precision: 0.9222 - recall: 0.8775\n",
      "Epoch 30/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2455 - accuracy: 0.8877 - precision: 0.9106 - recall: 0.9177\n",
      "Epoch 31/250\n",
      "2289/2289 [==============================] - 1s 357us/step - loss: 0.2642 - accuracy: 0.8659 - precision: 0.9153 - recall: 0.8837\n",
      "Epoch 32/250\n",
      "2289/2289 [==============================] - 1s 360us/step - loss: 0.2461 - accuracy: 0.8890 - precision: 0.9233 - recall: 0.8613\n",
      "Epoch 33/250\n",
      "2289/2289 [==============================] - 1s 379us/step - loss: 0.3386 - accuracy: 0.8488 - precision: 0.8591 - recall: 0.8439\n",
      "Epoch 34/250\n",
      "2289/2289 [==============================] - 1s 384us/step - loss: 0.2620 - accuracy: 0.8755 - precision: 0.9601 - recall: 0.8487\n",
      "Epoch 35/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2868 - accuracy: 0.8619 - precision: 0.9272 - recall: 0.8406\n",
      "Epoch 36/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2629 - accuracy: 0.8807 - precision: 0.9259 - recall: 0.8878\n",
      "Epoch 37/250\n",
      "2289/2289 [==============================] - 1s 323us/step - loss: 0.2388 - accuracy: 0.8829 - precision: 0.9253 - recall: 0.8827\n",
      "Epoch 38/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2312 - accuracy: 0.8956 - precision: 0.9206 - recall: 0.8927\n",
      "Epoch 39/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2550 - accuracy: 0.8777 - precision: 0.9327 - recall: 0.8645\n",
      "Epoch 40/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2659 - accuracy: 0.8759 - precision: 0.9273 - recall: 0.8359\n",
      "Epoch 41/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2790 - accuracy: 0.8598 - precision: 0.9509 - recall: 0.8020\n",
      "Epoch 42/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2453 - accuracy: 0.8681 - precision: 0.8835 - recall: 0.8959\n",
      "Epoch 43/250\n",
      "2289/2289 [==============================] - 1s 318us/step - loss: 0.2888 - accuracy: 0.8401 - precision: 0.8921 - recall: 0.8223\n",
      "Epoch 44/250\n",
      "2289/2289 [==============================] - 1s 323us/step - loss: 0.2631 - accuracy: 0.8698 - precision: 0.9278 - recall: 0.8743\n",
      "Epoch 45/250\n",
      "2289/2289 [==============================] - 1s 319us/step - loss: 0.2564 - accuracy: 0.8816 - precision: 0.9594 - recall: 0.8490\n",
      "Epoch 46/250\n",
      "2289/2289 [==============================] - 1s 316us/step - loss: 0.2614 - accuracy: 0.8576 - precision: 0.9469 - recall: 0.7993\n",
      "Epoch 47/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2633 - accuracy: 0.8689 - precision: 0.9382 - recall: 0.8082\n",
      "Epoch 48/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2444 - accuracy: 0.8820 - precision: 0.9522 - recall: 0.8766\n",
      "Epoch 49/250\n",
      "2289/2289 [==============================] - 1s 314us/step - loss: 0.2525 - accuracy: 0.8720 - precision: 0.9316 - recall: 0.8418\n",
      "Epoch 50/250\n",
      "2289/2289 [==============================] - 1s 324us/step - loss: 0.2493 - accuracy: 0.8768 - precision: 0.9341 - recall: 0.8291\n",
      "Epoch 51/250\n",
      "2289/2289 [==============================] - 1s 324us/step - loss: 0.2511 - accuracy: 0.8768 - precision: 0.9368 - recall: 0.8567\n",
      "Epoch 52/250\n",
      "2289/2289 [==============================] - 1s 320us/step - loss: 0.2294 - accuracy: 0.8912 - precision: 0.9575 - recall: 0.8593\n",
      "Epoch 53/250\n",
      "2289/2289 [==============================] - 1s 319us/step - loss: 0.2363 - accuracy: 0.9083 - precision: 0.9352 - recall: 0.8921\n",
      "Epoch 54/250\n",
      "2289/2289 [==============================] - 1s 315us/step - loss: 0.2183 - accuracy: 0.9004 - precision: 0.9409 - recall: 0.9132\n",
      "Epoch 55/250\n",
      "2289/2289 [==============================] - 1s 313us/step - loss: 0.2383 - accuracy: 0.8829 - precision: 0.8985 - recall: 0.8803\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289/2289 [==============================] - 1s 348us/step - loss: 0.2452 - accuracy: 0.8764 - precision: 0.9397 - recall: 0.8614\n",
      "Epoch 57/250\n",
      "2289/2289 [==============================] - 1s 482us/step - loss: 0.2513 - accuracy: 0.8860 - precision: 0.9490 - recall: 0.8704\n",
      "Epoch 58/250\n",
      "2289/2289 [==============================] - 1s 543us/step - loss: 0.2747 - accuracy: 0.8606 - precision: 0.9483 - recall: 0.7706\n",
      "Epoch 59/250\n",
      "2289/2289 [==============================] - 1s 379us/step - loss: 0.2226 - accuracy: 0.8938 - precision: 0.9236 - recall: 0.9218\n",
      "Epoch 60/250\n",
      "2289/2289 [==============================] - 1s 350us/step - loss: 0.2635 - accuracy: 0.8790 - precision: 0.9454 - recall: 0.8896\n",
      "Epoch 61/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.3068 - accuracy: 0.8419 - precision: 0.9017 - recall: 0.7983\n",
      "Epoch 62/250\n",
      "2289/2289 [==============================] - 1s 346us/step - loss: 0.2720 - accuracy: 0.8576 - precision: 0.8997 - recall: 0.8837\n",
      "Epoch 63/250\n",
      "2289/2289 [==============================] - 1s 387us/step - loss: 0.2434 - accuracy: 0.8781 - precision: 0.9133 - recall: 0.9065\n",
      "Epoch 64/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2390 - accuracy: 0.8877 - precision: 0.9285 - recall: 0.8681\n",
      "Epoch 65/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2314 - accuracy: 0.9043 - precision: 0.9422 - recall: 0.9205\n",
      "Epoch 66/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2714 - accuracy: 0.8764 - precision: 0.9574 - recall: 0.8387\n",
      "Epoch 67/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2197 - accuracy: 0.9113 - precision: 0.9314 - recall: 0.9230\n",
      "Epoch 68/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2416 - accuracy: 0.8925 - precision: 0.9025 - recall: 0.9178\n",
      "Epoch 69/250\n",
      "2289/2289 [==============================] - 1s 366us/step - loss: 0.2408 - accuracy: 0.8829 - precision: 0.9243 - recall: 0.8858\n",
      "Epoch 70/250\n",
      "2289/2289 [==============================] - 1s 427us/step - loss: 0.2529 - accuracy: 0.8825 - precision: 0.8976 - recall: 0.9033\n",
      "Epoch 71/250\n",
      "2289/2289 [==============================] - 1s 434us/step - loss: 0.2446 - accuracy: 0.8847 - precision: 0.9222 - recall: 0.8942\n",
      "Epoch 72/250\n",
      "2289/2289 [==============================] - 1s 406us/step - loss: 0.2514 - accuracy: 0.8777 - precision: 0.9362 - recall: 0.8538\n",
      "Epoch 73/250\n",
      "2289/2289 [==============================] - 1s 384us/step - loss: 0.2576 - accuracy: 0.8772 - precision: 0.9455 - recall: 0.8695\n",
      "Epoch 74/250\n",
      "2289/2289 [==============================] - 1s 353us/step - loss: 0.2433 - accuracy: 0.8842 - precision: 0.9565 - recall: 0.8905\n",
      "Epoch 75/250\n",
      "2289/2289 [==============================] - 1s 356us/step - loss: 0.2382 - accuracy: 0.8960 - precision: 0.9553 - recall: 0.8856\n",
      "Epoch 76/250\n",
      "2289/2289 [==============================] - 1s 336us/step - loss: 0.2724 - accuracy: 0.8519 - precision: 0.9137 - recall: 0.8240\n",
      "Epoch 77/250\n",
      "2289/2289 [==============================] - 1s 384us/step - loss: 0.2501 - accuracy: 0.8729 - precision: 0.9145 - recall: 0.8826\n",
      "Epoch 78/250\n",
      "2289/2289 [==============================] - 1s 392us/step - loss: 0.2772 - accuracy: 0.8785 - precision: 0.9364 - recall: 0.8809\n",
      "Epoch 79/250\n",
      "2289/2289 [==============================] - 1s 440us/step - loss: 0.3123 - accuracy: 0.8445 - precision: 0.9232 - recall: 0.8724\n",
      "Epoch 80/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.3441 - accuracy: 0.8279 - precision: 0.8842 - recall: 0.7800\n",
      "Epoch 81/250\n",
      "2289/2289 [==============================] - 1s 355us/step - loss: 0.2652 - accuracy: 0.8689 - precision: 0.9278 - recall: 0.8669\n",
      "Epoch 82/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2580 - accuracy: 0.8807 - precision: 0.9432 - recall: 0.8256\n",
      "Epoch 83/250\n",
      "2289/2289 [==============================] - 1s 357us/step - loss: 0.2398 - accuracy: 0.8799 - precision: 0.8839 - recall: 0.9195\n",
      "Epoch 84/250\n",
      "2289/2289 [==============================] - 1s 304us/step - loss: 0.2703 - accuracy: 0.8663 - precision: 0.9451 - recall: 0.7998\n",
      "Epoch 85/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2334 - accuracy: 0.8877 - precision: 0.9411 - recall: 0.8961\n",
      "Epoch 86/250\n",
      "2289/2289 [==============================] - 1s 403us/step - loss: 0.2236 - accuracy: 0.8973 - precision: 0.9219 - recall: 0.9028\n",
      "Epoch 87/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2506 - accuracy: 0.8873 - precision: 0.9166 - recall: 0.8469\n",
      "Epoch 88/250\n",
      "2289/2289 [==============================] - 1s 344us/step - loss: 0.2540 - accuracy: 0.8711 - precision: 0.9449 - recall: 0.8298\n",
      "Epoch 89/250\n",
      "2289/2289 [==============================] - 1s 318us/step - loss: 0.2183 - accuracy: 0.9013 - precision: 0.9632 - recall: 0.8779\n",
      "Epoch 90/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2349 - accuracy: 0.8921 - precision: 0.9239 - recall: 0.9026\n",
      "Epoch 91/250\n",
      "2289/2289 [==============================] - 1s 328us/step - loss: 0.2640 - accuracy: 0.8663 - precision: 0.9287 - recall: 0.8210\n",
      "Epoch 92/250\n",
      "2289/2289 [==============================] - 1s 340us/step - loss: 0.2522 - accuracy: 0.8742 - precision: 0.9359 - recall: 0.8523\n",
      "Epoch 93/250\n",
      "2289/2289 [==============================] - 1s 324us/step - loss: 0.2409 - accuracy: 0.8729 - precision: 0.9422 - recall: 0.8534\n",
      "Epoch 94/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2576 - accuracy: 0.8619 - precision: 0.9084 - recall: 0.8790\n",
      "Epoch 95/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2534 - accuracy: 0.8785 - precision: 0.9302 - recall: 0.8542\n",
      "Epoch 96/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2447 - accuracy: 0.8777 - precision: 0.9401 - recall: 0.8429\n",
      "Epoch 97/250\n",
      "2289/2289 [==============================] - 1s 416us/step - loss: 0.2793 - accuracy: 0.8633 - precision: 0.9674 - recall: 0.8148\n",
      "Epoch 98/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2651 - accuracy: 0.8847 - precision: 0.9406 - recall: 0.8439\n",
      "Epoch 99/250\n",
      "2289/2289 [==============================] - 1s 356us/step - loss: 0.2586 - accuracy: 0.8716 - precision: 0.9430 - recall: 0.8157\n",
      "Epoch 100/250\n",
      "2289/2289 [==============================] - 1s 352us/step - loss: 0.2472 - accuracy: 0.8886 - precision: 0.9471 - recall: 0.8842\n",
      "Epoch 101/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.2581 - accuracy: 0.8869 - precision: 0.9681 - recall: 0.9034\n",
      "Epoch 102/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2352 - accuracy: 0.8825 - precision: 0.9145 - recall: 0.8490\n",
      "Epoch 103/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2481 - accuracy: 0.8794 - precision: 0.9345 - recall: 0.9099\n",
      "Epoch 104/250\n",
      "2289/2289 [==============================] - 1s 314us/step - loss: 0.2199 - accuracy: 0.9035 - precision: 0.9326 - recall: 0.8984\n",
      "Epoch 105/250\n",
      "2289/2289 [==============================] - 1s 312us/step - loss: 0.2272 - accuracy: 0.9017 - precision: 0.9508 - recall: 0.8991 0s - loss: 0.2034 - accuracy: 0.9176 - precision: 0.9792 - rec\n",
      "Epoch 106/250\n",
      "2289/2289 [==============================] - 1s 316us/step - loss: 0.2643 - accuracy: 0.8820 - precision: 0.9384 - recall: 0.8234\n",
      "Epoch 107/250\n",
      "2289/2289 [==============================] - 1s 321us/step - loss: 0.2455 - accuracy: 0.8742 - precision: 0.9196 - recall: 0.8761\n",
      "Epoch 108/250\n",
      "2289/2289 [==============================] - 1s 364us/step - loss: 0.2566 - accuracy: 0.8777 - precision: 0.9176 - recall: 0.8909\n",
      "Epoch 109/250\n",
      "2289/2289 [==============================] - 1s 395us/step - loss: 0.2494 - accuracy: 0.8602 - precision: 0.9581 - recall: 0.8605\n",
      "Epoch 110/250\n",
      "2289/2289 [==============================] - 1s 393us/step - loss: 0.2340 - accuracy: 0.8982 - precision: 0.9545 - recall: 0.8783\n",
      "Epoch 111/250\n",
      "2289/2289 [==============================] - 1s 375us/step - loss: 0.2674 - accuracy: 0.8558 - precision: 0.9323 - recall: 0.8066\n",
      "Epoch 112/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289/2289 [==============================] - 1s 347us/step - loss: 0.2717 - accuracy: 0.8807 - precision: 0.9263 - recall: 0.8582\n",
      "Epoch 113/250\n",
      "2289/2289 [==============================] - 1s 352us/step - loss: 0.2327 - accuracy: 0.8991 - precision: 0.9606 - recall: 0.8689\n",
      "Epoch 114/250\n",
      "2289/2289 [==============================] - 1s 359us/step - loss: 0.2066 - accuracy: 0.9131 - precision: 0.9527 - recall: 0.9229\n",
      "Epoch 115/250\n",
      "2289/2289 [==============================] - 1s 364us/step - loss: 0.2272 - accuracy: 0.9013 - precision: 0.9573 - recall: 0.9179\n",
      "Epoch 116/250\n",
      "2289/2289 [==============================] - 1s 366us/step - loss: 0.2618 - accuracy: 0.8724 - precision: 0.9529 - recall: 0.8515\n",
      "Epoch 117/250\n",
      "2289/2289 [==============================] - 1s 342us/step - loss: 0.2351 - accuracy: 0.8943 - precision: 0.9698 - recall: 0.8676\n",
      "Epoch 118/250\n",
      "2289/2289 [==============================] - 1s 357us/step - loss: 0.2211 - accuracy: 0.8917 - precision: 0.9392 - recall: 0.8490\n",
      "Epoch 119/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2507 - accuracy: 0.8890 - precision: 0.9551 - recall: 0.8642\n",
      "Epoch 120/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2572 - accuracy: 0.8930 - precision: 0.9408 - recall: 0.8751\n",
      "Epoch 121/250\n",
      "2289/2289 [==============================] - 1s 357us/step - loss: 0.2638 - accuracy: 0.8702 - precision: 0.9575 - recall: 0.8166\n",
      "Epoch 122/250\n",
      "2289/2289 [==============================] - 1s 353us/step - loss: 0.2160 - accuracy: 0.9091 - precision: 0.9629 - recall: 0.8804\n",
      "Epoch 123/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2320 - accuracy: 0.8934 - precision: 0.9255 - recall: 0.9242\n",
      "Epoch 124/250\n",
      "2289/2289 [==============================] - 1s 353us/step - loss: 0.2575 - accuracy: 0.8785 - precision: 0.9308 - recall: 0.8605\n",
      "Epoch 125/250\n",
      "2289/2289 [==============================] - 1s 375us/step - loss: 0.2358 - accuracy: 0.8943 - precision: 0.9184 - recall: 0.9026\n",
      "Epoch 126/250\n",
      "2289/2289 [==============================] - 1s 328us/step - loss: 0.2043 - accuracy: 0.9083 - precision: 0.9342 - recall: 0.9172\n",
      "Epoch 127/250\n",
      "2289/2289 [==============================] - 1s 342us/step - loss: 0.2432 - accuracy: 0.8943 - precision: 0.9639 - recall: 0.8968\n",
      "Epoch 128/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.3425 - accuracy: 0.8287 - precision: 0.9424 - recall: 0.7493 0s - loss: 0.3372 - accuracy: 0.8320 - precision: 0.9395 - recall: 0.74\n",
      "Epoch 129/250\n",
      "2289/2289 [==============================] - 1s 375us/step - loss: 0.3287 - accuracy: 0.8375 - precision: 0.9709 - recall: 0.7647\n",
      "Epoch 130/250\n",
      "2289/2289 [==============================] - 1s 343us/step - loss: 0.2917 - accuracy: 0.8646 - precision: 0.9630 - recall: 0.8179\n",
      "Epoch 131/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2494 - accuracy: 0.8860 - precision: 0.9105 - recall: 0.9206\n",
      "Epoch 132/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.2261 - accuracy: 0.8991 - precision: 0.9396 - recall: 0.8959\n",
      "Epoch 133/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2823 - accuracy: 0.8536 - precision: 0.9202 - recall: 0.8184\n",
      "Epoch 134/250\n",
      "2289/2289 [==============================] - 1s 328us/step - loss: 0.2540 - accuracy: 0.8930 - precision: 0.9452 - recall: 0.8931\n",
      "Epoch 135/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2183 - accuracy: 0.9000 - precision: 0.9475 - recall: 0.9005\n",
      "Epoch 136/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2583 - accuracy: 0.8689 - precision: 0.9342 - recall: 0.8726\n",
      "Epoch 137/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2530 - accuracy: 0.8869 - precision: 0.9306 - recall: 0.8841\n",
      "Epoch 138/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2519 - accuracy: 0.8851 - precision: 0.9463 - recall: 0.8447\n",
      "Epoch 139/250\n",
      "2289/2289 [==============================] - 1s 321us/step - loss: 0.2460 - accuracy: 0.8908 - precision: 0.9599 - recall: 0.8676\n",
      "Epoch 140/250\n",
      "2289/2289 [==============================] - 1s 344us/step - loss: 0.2463 - accuracy: 0.8960 - precision: 0.9610 - recall: 0.8708\n",
      "Epoch 141/250\n",
      "2289/2289 [==============================] - 1s 365us/step - loss: 0.2636 - accuracy: 0.8711 - precision: 0.9436 - recall: 0.8294\n",
      "Epoch 142/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2307 - accuracy: 0.8790 - precision: 0.9425 - recall: 0.8382\n",
      "Epoch 143/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2462 - accuracy: 0.8851 - precision: 0.9353 - recall: 0.8783\n",
      "Epoch 144/250\n",
      "2289/2289 [==============================] - 1s 331us/step - loss: 0.2792 - accuracy: 0.8855 - precision: 0.9628 - recall: 0.8763\n",
      "Epoch 145/250\n",
      "2289/2289 [==============================] - 1s 347us/step - loss: 0.2825 - accuracy: 0.8724 - precision: 0.9674 - recall: 0.8348 0s - loss: 0.2394 - accuracy: 0.9020 - precision: 0.9733 - r\n",
      "Epoch 146/250\n",
      "2289/2289 [==============================] - 1s 348us/step - loss: 0.2354 - accuracy: 0.9043 - precision: 0.9314 - recall: 0.9311\n",
      "Epoch 147/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2597 - accuracy: 0.8707 - precision: 0.9398 - recall: 0.8503 0s - loss: 0.2777 - accuracy: 0.8936 - precision: 0.9577 - re\n",
      "Epoch 148/250\n",
      "2289/2289 [==============================] - 1s 339us/step - loss: 0.2672 - accuracy: 0.8685 - precision: 0.9057 - recall: 0.9068\n",
      "Epoch 149/250\n",
      "2289/2289 [==============================] - 1s 329us/step - loss: 0.2687 - accuracy: 0.8698 - precision: 0.9297 - recall: 0.8227\n",
      "Epoch 150/250\n",
      "2289/2289 [==============================] - 1s 380us/step - loss: 0.2372 - accuracy: 0.8952 - precision: 0.9141 - recall: 0.8872\n",
      "Epoch 151/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2294 - accuracy: 0.8973 - precision: 0.9126 - recall: 0.8779\n",
      "Epoch 152/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2273 - accuracy: 0.9017 - precision: 0.9365 - recall: 0.8869\n",
      "Epoch 153/250\n",
      "2289/2289 [==============================] - 1s 348us/step - loss: 0.2524 - accuracy: 0.8746 - precision: 0.9170 - recall: 0.9130\n",
      "Epoch 154/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2355 - accuracy: 0.8860 - precision: 0.9481 - recall: 0.8428\n",
      "Epoch 155/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2793 - accuracy: 0.8672 - precision: 0.9621 - recall: 0.8420\n",
      "Epoch 156/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2603 - accuracy: 0.8698 - precision: 0.9586 - recall: 0.8580 0s - loss: 0.2236 - accuracy: 0.8921 - precision: 0.9772 - reca\n",
      "Epoch 157/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2532 - accuracy: 0.8829 - precision: 0.9496 - recall: 0.8638\n",
      "Epoch 158/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2597 - accuracy: 0.8842 - precision: 0.9276 - recall: 0.8839\n",
      "Epoch 159/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2929 - accuracy: 0.8585 - precision: 0.9285 - recall: 0.8110\n",
      "Epoch 160/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2397 - accuracy: 0.8794 - precision: 0.9167 - recall: 0.8917\n",
      "Epoch 161/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2524 - accuracy: 0.8716 - precision: 0.9208 - recall: 0.8864\n",
      "Epoch 162/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2523 - accuracy: 0.8825 - precision: 0.9283 - recall: 0.8903\n",
      "Epoch 163/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2471 - accuracy: 0.8829 - precision: 0.9630 - recall: 0.8382\n",
      "Epoch 164/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2396 - accuracy: 0.8934 - precision: 0.9405 - recall: 0.8600\n",
      "Epoch 165/250\n",
      "2289/2289 [==============================] - 1s 315us/step - loss: 0.2765 - accuracy: 0.8650 - precision: 0.9596 - recall: 0.7886\n",
      "Epoch 166/250\n",
      "2289/2289 [==============================] - 1s 315us/step - loss: 0.2572 - accuracy: 0.8842 - precision: 0.9412 - recall: 0.8404\n",
      "Epoch 167/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289/2289 [==============================] - 1s 352us/step - loss: 0.2703 - accuracy: 0.8685 - precision: 0.9116 - recall: 0.8926\n",
      "Epoch 168/250\n",
      "2289/2289 [==============================] - 1s 360us/step - loss: 0.2611 - accuracy: 0.8742 - precision: 0.9548 - recall: 0.8694\n",
      "Epoch 169/250\n",
      "2289/2289 [==============================] - 1s 347us/step - loss: 0.2604 - accuracy: 0.8724 - precision: 0.9334 - recall: 0.8667\n",
      "Epoch 170/250\n",
      "2289/2289 [==============================] - 1s 367us/step - loss: 0.2381 - accuracy: 0.9017 - precision: 0.9648 - recall: 0.8955\n",
      "Epoch 171/250\n",
      "2289/2289 [==============================] - 1s 361us/step - loss: 0.2726 - accuracy: 0.8777 - precision: 0.9290 - recall: 0.8661\n",
      "Epoch 172/250\n",
      "2289/2289 [==============================] - 1s 310us/step - loss: 0.2275 - accuracy: 0.8921 - precision: 0.9609 - recall: 0.8543\n",
      "Epoch 173/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.2364 - accuracy: 0.9000 - precision: 0.9324 - recall: 0.9340\n",
      "Epoch 174/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2831 - accuracy: 0.8593 - precision: 0.9123 - recall: 0.8352\n",
      "Epoch 175/250\n",
      "2289/2289 [==============================] - 1s 349us/step - loss: 0.2269 - accuracy: 0.8882 - precision: 0.9197 - recall: 0.8598\n",
      "Epoch 176/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2428 - accuracy: 0.8781 - precision: 0.9609 - recall: 0.8357\n",
      "Epoch 177/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.2504 - accuracy: 0.8943 - precision: 0.9249 - recall: 0.9032\n",
      "Epoch 178/250\n",
      "2289/2289 [==============================] - 1s 351us/step - loss: 0.2426 - accuracy: 0.8947 - precision: 0.9549 - recall: 0.8734\n",
      "Epoch 179/250\n",
      "2289/2289 [==============================] - 1s 341us/step - loss: 0.3073 - accuracy: 0.8480 - precision: 0.9140 - recall: 0.8822\n",
      "Epoch 180/250\n",
      "2289/2289 [==============================] - 1s 291us/step - loss: 0.2831 - accuracy: 0.8624 - precision: 0.9607 - recall: 0.8116\n",
      "Epoch 181/250\n",
      "2289/2289 [==============================] - 1s 366us/step - loss: 0.2183 - accuracy: 0.8978 - precision: 0.9460 - recall: 0.9205\n",
      "Epoch 182/250\n",
      "2289/2289 [==============================] - 1s 349us/step - loss: 0.2391 - accuracy: 0.8781 - precision: 0.9183 - recall: 0.8531\n",
      "Epoch 183/250\n",
      "2289/2289 [==============================] - 1s 341us/step - loss: 0.3036 - accuracy: 0.8506 - precision: 0.9477 - recall: 0.8004\n",
      "Epoch 184/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2330 - accuracy: 0.8991 - precision: 0.9383 - recall: 0.9256\n",
      "Epoch 185/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2166 - accuracy: 0.9065 - precision: 0.9354 - recall: 0.9046\n",
      "Epoch 186/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2619 - accuracy: 0.8803 - precision: 0.9588 - recall: 0.8784\n",
      "Epoch 187/250\n",
      "2289/2289 [==============================] - 1s 342us/step - loss: 0.2831 - accuracy: 0.8733 - precision: 0.9639 - recall: 0.8725\n",
      "Epoch 188/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.3329 - accuracy: 0.8266 - precision: 0.9415 - recall: 0.7618\n",
      "Epoch 189/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.3285 - accuracy: 0.8344 - precision: 0.9485 - recall: 0.7747\n",
      "Epoch 190/250\n",
      "2289/2289 [==============================] - 1s 317us/step - loss: 0.3131 - accuracy: 0.8419 - precision: 0.9618 - recall: 0.7760\n",
      "Epoch 191/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2553 - accuracy: 0.8947 - precision: 0.9625 - recall: 0.8636\n",
      "Epoch 192/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.2196 - accuracy: 0.9017 - precision: 0.9431 - recall: 0.8509\n",
      "Epoch 193/250\n",
      "2289/2289 [==============================] - 1s 317us/step - loss: 0.2491 - accuracy: 0.8886 - precision: 0.9534 - recall: 0.9066\n",
      "Epoch 194/250\n",
      "2289/2289 [==============================] - 1s 320us/step - loss: 0.2425 - accuracy: 0.8925 - precision: 0.9609 - recall: 0.8540\n",
      "Epoch 195/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.3195 - accuracy: 0.8480 - precision: 0.9573 - recall: 0.8352\n",
      "Epoch 196/250\n",
      "2289/2289 [==============================] - 1s 318us/step - loss: 0.3219 - accuracy: 0.8405 - precision: 0.9588 - recall: 0.7517\n",
      "Epoch 197/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.3060 - accuracy: 0.8536 - precision: 0.9647 - recall: 0.7963\n",
      "Epoch 198/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2461 - accuracy: 0.8978 - precision: 0.9567 - recall: 0.8845\n",
      "Epoch 199/250\n",
      "2289/2289 [==============================] - 1s 344us/step - loss: 0.2155 - accuracy: 0.9100 - precision: 0.9068 - recall: 0.9321 0s - loss: 0.1901 - accuracy: 0.9100 - precision: 0.8382 - r\n",
      "Epoch 200/250\n",
      "2289/2289 [==============================] - 1s 412us/step - loss: 0.2605 - accuracy: 0.8742 - precision: 0.9175 - recall: 0.9076\n",
      "Epoch 201/250\n",
      "2289/2289 [==============================] - 1s 367us/step - loss: 0.2227 - accuracy: 0.9104 - precision: 0.9563 - recall: 0.9008\n",
      "Epoch 202/250\n",
      "2289/2289 [==============================] - 1s 371us/step - loss: 0.2138 - accuracy: 0.9017 - precision: 0.9422 - recall: 0.9315\n",
      "Epoch 203/250\n",
      "2289/2289 [==============================] - 1s 410us/step - loss: 0.2654 - accuracy: 0.8755 - precision: 0.9395 - recall: 0.8563\n",
      "Epoch 204/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2429 - accuracy: 0.8965 - precision: 0.9352 - recall: 0.9085\n",
      "Epoch 205/250\n",
      "2289/2289 [==============================] - 1s 319us/step - loss: 0.2298 - accuracy: 0.8930 - precision: 0.9326 - recall: 0.8796\n",
      "Epoch 206/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2750 - accuracy: 0.8812 - precision: 0.9258 - recall: 0.8972\n",
      "Epoch 207/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2511 - accuracy: 0.8711 - precision: 0.9390 - recall: 0.8170\n",
      "Epoch 208/250\n",
      "2289/2289 [==============================] - 1s 324us/step - loss: 0.2237 - accuracy: 0.9008 - precision: 0.9406 - recall: 0.8419\n",
      "Epoch 209/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2302 - accuracy: 0.9065 - precision: 0.9481 - recall: 0.8763\n",
      "Epoch 210/250\n",
      "2289/2289 [==============================] - 1s 326us/step - loss: 0.2109 - accuracy: 0.9144 - precision: 0.9550 - recall: 0.9004\n",
      "Epoch 211/250\n",
      "2289/2289 [==============================] - 1s 320us/step - loss: 0.3171 - accuracy: 0.8419 - precision: 0.9150 - recall: 0.8492\n",
      "Epoch 212/250\n",
      "2289/2289 [==============================] - 1s 332us/step - loss: 0.2455 - accuracy: 0.8903 - precision: 0.9356 - recall: 0.8713\n",
      "Epoch 213/250\n",
      "2289/2289 [==============================] - 1s 345us/step - loss: 0.2606 - accuracy: 0.8742 - precision: 0.9383 - recall: 0.8874\n",
      "Epoch 214/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2588 - accuracy: 0.8768 - precision: 0.9159 - recall: 0.8635\n",
      "Epoch 215/250\n",
      "2289/2289 [==============================] - 1s 301us/step - loss: 0.2170 - accuracy: 0.9096 - precision: 0.9487 - recall: 0.8952\n",
      "Epoch 216/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2233 - accuracy: 0.8855 - precision: 0.9012 - recall: 0.9130\n",
      "Epoch 217/250\n",
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2210 - accuracy: 0.9026 - precision: 0.9081 - recall: 0.9264\n",
      "Epoch 218/250\n",
      "2289/2289 [==============================] - 1s 309us/step - loss: 0.2211 - accuracy: 0.8982 - precision: 0.9248 - recall: 0.9180\n",
      "Epoch 219/250\n",
      "2289/2289 [==============================] - 1s 322us/step - loss: 0.2223 - accuracy: 0.8956 - precision: 0.9282 - recall: 0.9291\n",
      "Epoch 220/250\n",
      "2289/2289 [==============================] - 1s 313us/step - loss: 0.2293 - accuracy: 0.9030 - precision: 0.9346 - recall: 0.8986\n",
      "Epoch 221/250\n",
      "2289/2289 [==============================] - 1s 313us/step - loss: 0.2327 - accuracy: 0.8899 - precision: 0.9139 - recall: 0.8968\n",
      "Epoch 222/250\n",
      "2289/2289 [==============================] - 1s 313us/step - loss: 0.2288 - accuracy: 0.8930 - precision: 0.9517 - recall: 0.9198\n",
      "Epoch 223/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289/2289 [==============================] - 1s 325us/step - loss: 0.2090 - accuracy: 0.9065 - precision: 0.9430 - recall: 0.9122\n",
      "Epoch 224/250\n",
      "2289/2289 [==============================] - 1s 351us/step - loss: 0.2329 - accuracy: 0.8925 - precision: 0.9304 - recall: 0.9054\n",
      "Epoch 225/250\n",
      "2289/2289 [==============================] - 1s 340us/step - loss: 0.2300 - accuracy: 0.9104 - precision: 0.9311 - recall: 0.9211\n",
      "Epoch 226/250\n",
      "2289/2289 [==============================] - 1s 352us/step - loss: 0.2511 - accuracy: 0.8781 - precision: 0.8913 - recall: 0.8960\n",
      "Epoch 227/250\n",
      "2289/2289 [==============================] - 1s 357us/step - loss: 0.2428 - accuracy: 0.8834 - precision: 0.9253 - recall: 0.8738\n",
      "Epoch 228/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2478 - accuracy: 0.8847 - precision: 0.9584 - recall: 0.8637\n",
      "Epoch 229/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.3446 - accuracy: 0.8292 - precision: 0.9442 - recall: 0.7587\n",
      "Epoch 230/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2447 - accuracy: 0.9004 - precision: 0.9668 - recall: 0.8326\n",
      "Epoch 231/250\n",
      "2289/2289 [==============================] - 1s 341us/step - loss: 0.2881 - accuracy: 0.8646 - precision: 0.9693 - recall: 0.8107\n",
      "Epoch 232/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2332 - accuracy: 0.9222 - precision: 0.9641 - recall: 0.8941\n",
      "Epoch 233/250\n",
      "2289/2289 [==============================] - 1s 338us/step - loss: 0.2065 - accuracy: 0.9218 - precision: 0.9779 - recall: 0.9135\n",
      "Epoch 234/250\n",
      "2289/2289 [==============================] - 1s 355us/step - loss: 0.2389 - accuracy: 0.8995 - precision: 0.9547 - recall: 0.8993\n",
      "Epoch 235/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2134 - accuracy: 0.9061 - precision: 0.8977 - recall: 0.9143\n",
      "Epoch 236/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2399 - accuracy: 0.8947 - precision: 0.9473 - recall: 0.8956\n",
      "Epoch 237/250\n",
      "2289/2289 [==============================] - 1s 334us/step - loss: 0.2190 - accuracy: 0.9122 - precision: 0.9432 - recall: 0.9439\n",
      "Epoch 238/250\n",
      "2289/2289 [==============================] - 1s 348us/step - loss: 0.2276 - accuracy: 0.8921 - precision: 0.9282 - recall: 0.8959\n",
      "Epoch 239/250\n",
      "2289/2289 [==============================] - 1s 337us/step - loss: 0.2225 - accuracy: 0.8903 - precision: 0.9125 - recall: 0.9414\n",
      "Epoch 240/250\n",
      "2289/2289 [==============================] - 1s 330us/step - loss: 0.3052 - accuracy: 0.8414 - precision: 0.8882 - recall: 0.8695\n",
      "Epoch 241/250\n",
      "2289/2289 [==============================] - 1s 327us/step - loss: 0.2670 - accuracy: 0.8646 - precision: 0.9374 - recall: 0.8380\n",
      "Epoch 242/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2379 - accuracy: 0.8869 - precision: 0.9153 - recall: 0.9188\n",
      "Epoch 243/250\n",
      "2289/2289 [==============================] - 1s 354us/step - loss: 0.2702 - accuracy: 0.8711 - precision: 0.9535 - recall: 0.8710\n",
      "Epoch 244/250\n",
      "2289/2289 [==============================] - 1s 340us/step - loss: 0.1744 - accuracy: 0.9345 - precision: 0.9438 - recall: 0.9449\n",
      "Epoch 245/250\n",
      "2289/2289 [==============================] - 1s 320us/step - loss: 0.2014 - accuracy: 0.9196 - precision: 0.9611 - recall: 0.9310\n",
      "Epoch 246/250\n",
      "2289/2289 [==============================] - 1s 335us/step - loss: 0.2066 - accuracy: 0.9144 - precision: 0.9575 - recall: 0.9340\n",
      "Epoch 247/250\n",
      "2289/2289 [==============================] - 1s 328us/step - loss: 0.2114 - accuracy: 0.9039 - precision: 0.9385 - recall: 0.8907\n",
      "Epoch 248/250\n",
      "2289/2289 [==============================] - 1s 347us/step - loss: 0.2576 - accuracy: 0.8807 - precision: 0.9548 - recall: 0.8724\n",
      "Epoch 249/250\n",
      "2289/2289 [==============================] - 1s 349us/step - loss: 0.2352 - accuracy: 0.9144 - precision: 0.9657 - recall: 0.9184\n",
      "Epoch 250/250\n",
      "2289/2289 [==============================] - 1s 333us/step - loss: 0.2396 - accuracy: 0.8934 - precision: 0.9507 - recall: 0.9030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1287e88d348>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_metrics as km\n",
    "# Compile model\n",
    "model_1.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy',km.binary_precision(), km.binary_recall()])\n",
    "\n",
    "# Train model\n",
    "model_1.fit(X_train, y_train_cat, epochs=250, batch_size=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above model is trained with training accuracy  89%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 0s 1ms/step\n",
      "Accuracy on Test samples: 0.9764705896377563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model's performance on the test data\n",
    "performance_test = model_1.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy on Test samples: {0}\".format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model predicts whether a fellow will be placed oe not with 97% accuracy. Precision and recall are close to 1. This means that the model is relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An accuracy calculating function\n",
    "\n",
    "def accuracy(y,Y_pred):\n",
    "  count = 0\n",
    "  for i,val in enumerate(y):\n",
    "    if (val == Y_pred[i]):\n",
    "      count = count + 1\n",
    "  accuracy = count/y.shape[0]\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 50)\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with decision tree approach for test set =  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "print(\"Accuracy with decision tree approach for test set = \",accuracy(Y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: If placed, how long will it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering to get data of those candidates placed\n",
    "df_X_new = df_X[df_Y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 118)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathrise_status_Active</th>\n",
       "      <th>pathrise_status_Closed Lost</th>\n",
       "      <th>pathrise_status_Placed</th>\n",
       "      <th>pathrise_status_Withdrawn (Failed)</th>\n",
       "      <th>pathrise_status_Withdrawn (Trial)</th>\n",
       "      <th>pathrise_status_Withdrawn</th>\n",
       "      <th>pathrise_status_Deferred</th>\n",
       "      <th>pathrise_status_Break</th>\n",
       "      <th>pathrise_status_MIA</th>\n",
       "      <th>primary_track_SWE</th>\n",
       "      <th>...</th>\n",
       "      <th>race_Decline to Self Identify</th>\n",
       "      <th>race_Black, Afro-Caribbean, or African American</th>\n",
       "      <th>race_Latino or Hispanic American</th>\n",
       "      <th>race_Middle Eastern or Arab American</th>\n",
       "      <th>race_South Asian or Indian American</th>\n",
       "      <th>race_Two or More Races</th>\n",
       "      <th>race_Native American or Alaskan Native</th>\n",
       "      <th>program_duration_days</th>\n",
       "      <th>number_of_interviews</th>\n",
       "      <th>number_of_applications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pathrise_status_Active  pathrise_status_Closed Lost  \\\n",
       "4                        0                            0   \n",
       "23                       0                            0   \n",
       "30                       0                            0   \n",
       "39                       0                            0   \n",
       "54                       0                            0   \n",
       "\n",
       "    pathrise_status_Placed  pathrise_status_Withdrawn (Failed)  \\\n",
       "4                        1                                   0   \n",
       "23                       1                                   0   \n",
       "30                       1                                   0   \n",
       "39                       1                                   0   \n",
       "54                       1                                   0   \n",
       "\n",
       "    pathrise_status_Withdrawn (Trial)  pathrise_status_Withdrawn  \\\n",
       "4                                   0                          0   \n",
       "23                                  0                          0   \n",
       "30                                  0                          0   \n",
       "39                                  0                          0   \n",
       "54                                  0                          0   \n",
       "\n",
       "    pathrise_status_Deferred  pathrise_status_Break  pathrise_status_MIA  \\\n",
       "4                          0                      0                    0   \n",
       "23                         0                      0                    0   \n",
       "30                         0                      0                    0   \n",
       "39                         0                      0                    0   \n",
       "54                         0                      0                    0   \n",
       "\n",
       "    primary_track_SWE  ...  race_Decline to Self Identify  \\\n",
       "4                   1  ...                              0   \n",
       "23                  0  ...                              0   \n",
       "30                  1  ...                              0   \n",
       "39                  1  ...                              0   \n",
       "54                  1  ...                              0   \n",
       "\n",
       "    race_Black, Afro-Caribbean, or African American  \\\n",
       "4                                                 0   \n",
       "23                                                0   \n",
       "30                                                0   \n",
       "39                                                0   \n",
       "54                                                0   \n",
       "\n",
       "    race_Latino or Hispanic American  race_Middle Eastern or Arab American  \\\n",
       "4                                  0                                     0   \n",
       "23                                 0                                     0   \n",
       "30                                 0                                     0   \n",
       "39                                 0                                     0   \n",
       "54                                 0                                     0   \n",
       "\n",
       "    race_South Asian or Indian American  race_Two or More Races  \\\n",
       "4                                     0                       0   \n",
       "23                                    0                       0   \n",
       "30                                    0                       0   \n",
       "39                                    0                       0   \n",
       "54                                    0                       0   \n",
       "\n",
       "    race_Native American or Alaskan Native  program_duration_days  \\\n",
       "4                                        0                   89.0   \n",
       "23                                       0                  193.0   \n",
       "30                                       0                   73.0   \n",
       "39                                       1                   83.0   \n",
       "54                                       0                   76.0   \n",
       "\n",
       "    number_of_interviews  number_of_applications  \n",
       "4                   10.0                     100  \n",
       "23                   5.0                       4  \n",
       "30                   0.0                       1  \n",
       "39                   0.0                      15  \n",
       "54                   0.0                      30  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-5 months\n",
      "Less than one month\n",
      "1-2 months\n",
      "6 months to a year\n",
      "Over a year\n"
     ]
    }
   ],
   "source": [
    "#length of job search is the interested result. So, removing all the columns related to that and this\n",
    "# is a classification problem with 5 classes with 3-5 months as class 0, less than one month as class 1 and so on.\n",
    "for i in all_uniques_encoded['length_of_job_search']:\n",
    "    df_X_new = df_X_new.drop('length_of_job_search_'+i, axis=1)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 113)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting text to obtain class numbers such as 0,1,2,3 and 4\n",
    "df_Y_new = data.groupby(['length_of_job_search']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2544"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(max(df_Y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows of those that were not placed\n",
    "df_Y_new = df_Y_new[df_Y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956,)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_placed = df_X_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_placed = df_Y_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_placed_shape =  (860, 113)\n",
      "X_test_placed_shape =  (96, 113)\n"
     ]
    }
   ],
   "source": [
    "X_train_placed, X_test_placed, Y_train_placed, Y_test_placed = train_test_split(X_placed, Y_placed, test_size=0.1, random_state=4)\n",
    "print('X_train_placed_shape = ', X_train_placed.shape)\n",
    "print('X_test_placed_shape = ', X_test_placed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_placed_cat shape =  (860, 5)\n",
      "y_test_placed_cat shape =  (96, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train_placed_cat = to_categorical(Y_train_placed)\n",
    "y_test_placed_cat = to_categorical(Y_test_placed)\n",
    "\n",
    "print('y_train_placed_cat shape = ', y_train_placed_cat.shape)\n",
    "print('y_test_placed_cat shape = ', y_test_placed_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_hidden_layer (Dense)   (None, 100)               11400     \n",
      "_________________________________________________________________\n",
      "second_hidden_layer (Dense)  (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "third_hidden_layer (Dense)   (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "forth_hidden_layer (Dense)   (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "fifth_hidden_layer (Dense)   (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "sixth_hidden_layer (Dense)   (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 623,605\n",
      "Trainable params: 623,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore some warning logs\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "#  Define a Feed-Forward Model with 2 hidden layers with dimensions 392 and 196 Neurons\n",
    "model_2 = Sequential([\n",
    "  Dense(100, activation='relu', input_shape=(113,), name=\"first_hidden_layer\"),\n",
    "  Dense(500, activation='relu', name=\"second_hidden_layer\"), Dropout(0.5),\n",
    "  Dense(500,activation= 'relu',name = \"third_hidden_layer\"),\n",
    "  Dense(500,activation= 'relu',name = \"forth_hidden_layer\"),\n",
    "  Dense(100,activation= 'relu',name = \"fifth_hidden_layer\"),\n",
    "  Dense(100,activation= 'relu',name = \"sixth_hidden_layer\"),\n",
    "  Dense(5, activation='softmax'),\n",
    "])\n",
    "\n",
    "#  Validate your Model Architecture\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
      "Epoch 1/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: 1.6693 - accuracy: 0.3000 - precision: 0.3260 - recall: 0.1291\n",
      "Epoch 2/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4990 - accuracy: 0.3267 - precision: 0.3260 - recall: 0.0840\n",
      "Epoch 3/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4857 - accuracy: 0.3198 - precision: 0.1760 - recall: 0.0092\n",
      "Epoch 4/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4783 - accuracy: 0.3314 - precision: 0.3541 - recall: 0.0317\n",
      "Epoch 5/100\n",
      "860/860 [==============================] - 1s 998us/step - loss: 1.4785 - accuracy: 0.3116 - precision: 0.5873 - recall: 0.0228\n",
      "Epoch 6/100\n",
      "860/860 [==============================] - 1s 991us/step - loss: 1.4798 - accuracy: 0.3360 - precision: 0.3973 - recall: 0.0136\n",
      "Epoch 7/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4657 - accuracy: 0.3395 - precision: 0.2589 - recall: 0.0133\n",
      "Epoch 8/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4678 - accuracy: 0.3326 - precision: 0.2632 - recall: 0.0200\n",
      "Epoch 9/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4698 - accuracy: 0.3314 - precision: 0.4883 - recall: 0.0299\n",
      "Epoch 10/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4626 - accuracy: 0.3279 - precision: 0.1462 - recall: 0.0062\n",
      "Epoch 11/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4639 - accuracy: 0.3326 - precision: 0.3960 - recall: 0.0145\n",
      "Epoch 12/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4621 - accuracy: 0.3628 - precision: 0.4494 - recall: 0.0176\n",
      "Epoch 13/100\n",
      "860/860 [==============================] - 1s 993us/step - loss: 1.4644 - accuracy: 0.3360 - precision: 0.6847 - recall: 0.0119\n",
      "Epoch 14/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4605 - accuracy: 0.3465 - precision: 0.6075 - recall: 0.0164\n",
      "Epoch 15/100\n",
      "860/860 [==============================] - 1s 975us/step - loss: 1.4597 - accuracy: 0.3430 - precision: 0.5047 - recall: 0.0245\n",
      "Epoch 16/100\n",
      "860/860 [==============================] - 1s 992us/step - loss: 1.4564 - accuracy: 0.3302 - precision: 0.6860 - recall: 0.0114\n",
      "Epoch 17/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4605 - accuracy: 0.3395 - precision: 0.7614 - recall: 0.0277\n",
      "Epoch 18/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4562 - accuracy: 0.3326 - precision: 0.8256 - recall: 0.0090\n",
      "Epoch 19/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4539 - accuracy: 0.3326 - precision: 0.6868 - recall: 0.0146\n",
      "Epoch 20/100\n",
      "860/860 [==============================] - 1s 991us/step - loss: 1.4513 - accuracy: 0.3314 - precision: 0.4665 - recall: 0.0090\n",
      "Epoch 21/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4520 - accuracy: 0.3279 - precision: 0.6041 - recall: 0.0079\n",
      "Epoch 22/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4557 - accuracy: 0.3244 - precision: 0.5386 - recall: 0.0227   - ETA: 0s - loss: 1.4108 - accuracy: 0.3562 - precision: 0.7604 - \n",
      "Epoch 23/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4554 - accuracy: 0.3384 - precision: 0.5833 - recall: 0.0065\n",
      "Epoch 24/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4559 - accuracy: 0.3326 - precision: 0.6404 - recall: 0.0213\n",
      "Epoch 25/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4507 - accuracy: 0.3442 - precision: 0.6831 - recall: 0.0275\n",
      "Epoch 26/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4546 - accuracy: 0.3407 - precision: 0.6650 - recall: 0.0213\n",
      "Epoch 27/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4555 - accuracy: 0.3360 - precision: 0.6694 - recall: 0.0137\n",
      "Epoch 28/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4525 - accuracy: 0.3279 - precision: 0.3640 - recall: 0.0098\n",
      "Epoch 29/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4511 - accuracy: 0.3349 - precision: 0.1715 - recall: 0.0015 \n",
      "Epoch 30/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4521 - accuracy: 0.3430 - precision: 0.4582 - recall: 0.0147\n",
      "Epoch 31/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4538 - accuracy: 0.3302 - precision: 0.6471 - recall: 0.0111\n",
      "Epoch 32/100\n",
      "860/860 [==============================] - 1s 991us/step - loss: 1.4501 - accuracy: 0.3442 - precision: 0.9651 - recall: 0.0130\n",
      "Epoch 33/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4528 - accuracy: 0.3407 - precision: 0.3607 - recall: 0.0063\n",
      "Epoch 34/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4528 - accuracy: 0.3384 - precision: 0.5705 - recall: 0.0195\n",
      "Epoch 35/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4512 - accuracy: 0.3233 - precision: 0.7865 - recall: 0.0404- ETA: 0s - loss: 1.3902 - accuracy: 0.3324 - precision: 0.9391 - rec\n",
      "Epoch 36/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4502 - accuracy: 0.3279 - precision: 0.6632 - recall: 0.0081\n",
      "Epoch 37/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4506 - accuracy: 0.3267 - precision: 0.6219 - recall: 0.0139\n",
      "Epoch 38/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4510 - accuracy: 0.3407 - precision: 0.7217 - recall: 0.0421\n",
      "Epoch 39/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4519 - accuracy: 0.3314 - precision: 0.7907 - recall: 0.0117\n",
      "Epoch 40/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4515 - accuracy: 0.3395 - precision: 0.6178 - recall: 0.0247\n",
      "Epoch 41/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4473 - accuracy: 0.3267 - precision: 0.6948 - recall: 0.0145\n",
      "Epoch 42/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4496 - accuracy: 0.3477 - precision: 0.6519 - recall: 0.0266TA: 0s - loss: 1.4504 - accuracy: 0.3440 - precision: 0.7220 - recall\n",
      "Epoch 43/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4502 - accuracy: 0.3407 - precision: 0.3857 - recall: 0.0108\n",
      "Epoch 44/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4470 - accuracy: 0.3302 - precision: 0.6260 - recall: 0.0162\n",
      "Epoch 45/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4503 - accuracy: 0.3349 - precision: 0.4849 - recall: 0.0161\n",
      "Epoch 46/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4474 - accuracy: 0.3372 - precision: 0.8177 - recall: 0.0329\n",
      "Epoch 47/100\n",
      "860/860 [==============================] - 1s 971us/step - loss: 1.4488 - accuracy: 0.3384 - precision: 0.7337 - recall: 0.0190\n",
      "Epoch 48/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4493 - accuracy: 0.3314 - precision: 0.8378 - recall: 0.0132\n",
      "Epoch 49/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4485 - accuracy: 0.3093 - precision: 0.2469 - recall: 0.0065\n",
      "Epoch 50/100\n",
      "860/860 [==============================] - 1s 989us/step - loss: 1.4507 - accuracy: 0.3430 - precision: 0.7701 - recall: 0.0368\n",
      "Epoch 51/100\n",
      "860/860 [==============================] - 1s 942us/step - loss: 1.4451 - accuracy: 0.3395 - precision: 0.6748 - recall: 0.0111\n",
      "Epoch 52/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4487 - accuracy: 0.3465 - precision: 0.5810 - recall: 0.0237\n",
      "Epoch 53/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4454 - accuracy: 0.3407 - precision: 0.8379 - recall: 0.0226\n",
      "Epoch 54/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4444 - accuracy: 0.3279 - precision: 0.8165 - recall: 0.0448\n",
      "Epoch 55/100\n",
      "860/860 [==============================] - 1s 969us/step - loss: 1.4498 - accuracy: 0.3267 - precision: 0.3601 - recall: 0.0088\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4474 - accuracy: 0.3302 - precision: 0.6837 - recall: 0.0234\n",
      "Epoch 57/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4481 - accuracy: 0.3384 - precision: 0.8143 - recall: 0.0315\n",
      "Epoch 58/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4484 - accuracy: 0.3477 - precision: 0.5879 - recall: 0.0253\n",
      "Epoch 59/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4469 - accuracy: 0.3453 - precision: 0.4694 - recall: 0.0160\n",
      "Epoch 60/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4498 - accuracy: 0.3279 - precision: 0.3622 - recall: 0.0243\n",
      "Epoch 61/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4497 - accuracy: 0.3267 - precision: 0.6548 - recall: 0.0502\n",
      "Epoch 62/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4488 - accuracy: 0.3337 - precision: 0.8508 - recall: 0.0302\n",
      "Epoch 63/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4471 - accuracy: 0.3372 - precision: 0.6017 - recall: 0.0178\n",
      "Epoch 64/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4488 - accuracy: 0.3291 - precision: 0.6270 - recall: 0.0215\n",
      "Epoch 65/100\n",
      "860/860 [==============================] - 1s 972us/step - loss: 1.4451 - accuracy: 0.3419 - precision: 0.6146 - recall: 0.0102\n",
      "Epoch 66/100\n",
      "860/860 [==============================] - 1s 985us/step - loss: 1.4454 - accuracy: 0.3384 - precision: 0.5016 - recall: 0.0294\n",
      "Epoch 67/100\n",
      "860/860 [==============================] - 1s 998us/step - loss: 1.4476 - accuracy: 0.3384 - precision: 0.6700 - recall: 0.0188\n",
      "Epoch 68/100\n",
      "860/860 [==============================] - 1s 984us/step - loss: 1.4477 - accuracy: 0.3337 - precision: 0.6712 - recall: 0.0283\n",
      "Epoch 69/100\n",
      "860/860 [==============================] - 1s 989us/step - loss: 1.4463 - accuracy: 0.3349 - precision: 0.7121 - recall: 0.0271\n",
      "Epoch 70/100\n",
      "860/860 [==============================] - 1s 990us/step - loss: 1.4472 - accuracy: 0.3337 - precision: 0.6022 - recall: 0.0302 0s - loss: 1.4493 - accuracy: 0.3361 - precision: 0.6117 - recall: 0.0\n",
      "Epoch 71/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4457 - accuracy: 0.3477 - precision: 0.7590 - recall: 0.0195\n",
      "Epoch 72/100\n",
      "860/860 [==============================] - 1s 1000us/step - loss: 1.4494 - accuracy: 0.3349 - precision: 0.5592 - recall: 0.0103\n",
      "Epoch 73/100\n",
      "860/860 [==============================] - 1s 988us/step - loss: 1.4466 - accuracy: 0.3326 - precision: 0.7891 - recall: 0.0386\n",
      "Epoch 74/100\n",
      "860/860 [==============================] - 1s 984us/step - loss: 1.4465 - accuracy: 0.3267 - precision: 0.7120 - recall: 0.0318\n",
      "Epoch 75/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4483 - accuracy: 0.3407 - precision: 0.8714 - recall: 0.0242\n",
      "Epoch 76/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4473 - accuracy: 0.3395 - precision: 0.5334 - recall: 0.0141\n",
      "Epoch 77/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4449 - accuracy: 0.3442 - precision: 0.5454 - recall: 0.0173\n",
      "Epoch 78/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4425 - accuracy: 0.3395 - precision: 0.2949 - recall: 0.0091\n",
      "Epoch 79/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4477 - accuracy: 0.3360 - precision: 0.5967 - recall: 0.0310\n",
      "Epoch 80/100\n",
      "860/860 [==============================] - 1s 979us/step - loss: 1.4491 - accuracy: 0.3279 - precision: 0.7093 - recall: 0.0288 - ETA: 0s - loss: 1.4816 - accuracy: 0.3105 - precision: 0.7895 - re\n",
      "Epoch 81/100\n",
      "860/860 [==============================] - 1s 983us/step - loss: 1.4462 - accuracy: 0.3279 - precision: 0.5228 - recall: 0.0237\n",
      "Epoch 82/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4470 - accuracy: 0.3291 - precision: 0.6959 - recall: 0.0333\n",
      "Epoch 83/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4476 - accuracy: 0.3442 - precision: 0.2915 - recall: 0.0089\n",
      "Epoch 84/100\n",
      "860/860 [==============================] - 1s 999us/step - loss: 1.4488 - accuracy: 0.3360 - precision: 0.5905 - recall: 0.0390\n",
      "Epoch 85/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4479 - accuracy: 0.3395 - precision: 0.8059 - recall: 0.0253\n",
      "Epoch 86/100\n",
      "860/860 [==============================] - 1s 973us/step - loss: 1.4461 - accuracy: 0.3407 - precision: 0.6395 - recall: 0.0242\n",
      "Epoch 87/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4447 - accuracy: 0.3523 - precision: 0.4125 - recall: 0.0141\n",
      "Epoch 88/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4450 - accuracy: 0.3419 - precision: 0.5415 - recall: 0.0317\n",
      "Epoch 89/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4484 - accuracy: 0.3221 - precision: 0.4328 - recall: 0.0140\n",
      "Epoch 90/100\n",
      "860/860 [==============================] - 1s 982us/step - loss: 1.4481 - accuracy: 0.3302 - precision: 0.3977 - recall: 0.0132\n",
      "Epoch 91/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4477 - accuracy: 0.3256 - precision: 0.6329 - recall: 0.0198\n",
      "Epoch 92/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4464 - accuracy: 0.3477 - precision: 0.5064 - recall: 0.0331\n",
      "Epoch 93/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4468 - accuracy: 0.3233 - precision: 0.7528 - recall: 0.0309\n",
      "Epoch 94/100\n",
      "860/860 [==============================] - 1s 962us/step - loss: 1.4473 - accuracy: 0.3360 - precision: 0.5350 - recall: 0.0232\n",
      "Epoch 95/100\n",
      "860/860 [==============================] - 1s 952us/step - loss: 1.4467 - accuracy: 0.3326 - precision: 0.7390 - recall: 0.0303\n",
      "Epoch 96/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4441 - accuracy: 0.3349 - precision: 0.8659 - recall: 0.0144TA: 0s - loss: 1.4550 - accuracy: 0.3327 - precision: 0.8364 - recall:\n",
      "Epoch 97/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4469 - accuracy: 0.3314 - precision: 0.6513 - recall: 0.0269\n",
      "Epoch 98/100\n",
      "860/860 [==============================] - 1s 988us/step - loss: 1.4459 - accuracy: 0.3477 - precision: 0.5583 - recall: 0.0217\n",
      "Epoch 99/100\n",
      "860/860 [==============================] - 1s 1ms/step - loss: 1.4480 - accuracy: 0.3267 - precision: 0.8453 - recall: 0.0144\n",
      "Epoch 100/100\n",
      "860/860 [==============================] - 1s 968us/step - loss: 1.4468 - accuracy: 0.3337 - precision: 0.8272 - recall: 0.0373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1287eb78b08>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_metrics as km\n",
    "# Compile model\n",
    "model_2.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy',km.binary_precision(), km.binary_recall()])\n",
    "\n",
    "# Train model\n",
    "model_2.fit(X_train_placed, y_train_placed_cat, epochs=100, batch_size=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above model is not useful in predicting how long it will take for a fellow to get placed. One main reason is that for neural networks, we need more data to get a good model with neural networks, also if recall is bad, model is also bad and recall of this model is horrendous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step\n",
      "Accuracy on Test samples: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model's performance on the test data\n",
    "performance_test_model_2 = model_2.evaluate(X_test_placed, y_test_placed_cat)\n",
    "print(\"Accuracy on Test samples: {0}\".format(performance_test_model_2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with decision tree approach for test set =  0.28125\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf_placed = tree.DecisionTreeClassifier(max_depth = 100,random_state=300)\n",
    "clf_placed = clf_placed.fit(X_train_placed, Y_train_placed)\n",
    "\n",
    "y_pred_test_placed = clf_placed.predict(X_test_placed)\n",
    "print(\"Accuracy with decision tree approach for test set = \",accuracy(Y_test_placed,y_pred_test_placed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above model doesn't give a good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c =  0.8 kernel =  rbf acc =  0.3125\n",
      "c =  1 kernel =  rbf acc =  0.3125\n",
      "c =  1.5 kernel =  rbf acc =  0.28125\n",
      "c =  10 kernel =  rbf acc =  0.3020833333333333\n",
      "c =  0.8 kernel =  sigmoid acc =  0.2604166666666667\n",
      "c =  1 kernel =  sigmoid acc =  0.2604166666666667\n",
      "c =  1.5 kernel =  sigmoid acc =  0.3645833333333333\n",
      "c =  10 kernel =  sigmoid acc =  0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C_list = [0.8,1,1.5,10]\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "  for c in C_list:\n",
    "    #print(c)\n",
    "    clf_svm = svm.SVC(C = c,kernel=kernel,random_state=20)\n",
    "    clf_svm.fit(X_train_placed,Y_train_placed)\n",
    "    y_pred_placed_svm = clf_svm.predict(X_test_placed)\n",
    "    acc = accuracy(Y_test_placed,y_pred_placed_svm)\n",
    "    print(\"c = \",c,\"kernel = \",kernel,\"acc = \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=150, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=500,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#max_depth = [2,3,4,5,6]\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=150, random_state=500)\n",
    "clf_rf.fit(X_train_placed, Y_train_placed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with decision tree approach for test set =  0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_placed_rf = clf_rf.predict(X_test_placed)\n",
    "print(\"Accuracy with decision tree approach for test set = \",accuracy(Y_test_placed,y_pred_test_placed_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf_fs = ExtraTreesClassifier(n_estimators=250)\n",
    "clf_fs = clf_fs.fit(X_placed, Y_placed)\n",
    "#clf_fs.feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(clf_fs, prefit=True)\n",
    "X_new = model.transform(X_placed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 37)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_placed_shape =  (860, 37)\n",
      "X_test_placed_shape =  (96, 37)\n"
     ]
    }
   ],
   "source": [
    "X_train_new_placed, X_test_new_placed, Y_train_new_placed, Y_test_new_placed = train_test_split(X_new, Y_placed, test_size=0.1, random_state=4)\n",
    "print('X_train_placed_shape = ', X_train_new_placed.shape)\n",
    "print('X_test_placed_shape = ', X_test_new_placed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#max_depth = [2,3,4,5,6]\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=50, random_state=100)\n",
    "clf_rf.fit(X_train_new_placed, Y_train_new_placed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with decision tree approach for test set =  0.3125\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_placed_rf = clf_rf.predict(X_test_new_placed)\n",
    "print(\"Accuracy with decision tree approach for test set = \",accuracy(Y_test_new_placed,y_pred_test_placed_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation and reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_placed_pca = pca.fit_transform(X_placed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 50)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_placed_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca_placed =  (860, 50)\n",
      "X_test_pca_placed =  (96, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_pca_placed, X_test_pca_placed, Y_train_pca_placed, Y_test_pca_placed = train_test_split(X_placed_pca, Y_placed, test_size=0.1, random_state=4)\n",
    "print('X_train_pca_placed = ', X_train_pca_placed.shape)\n",
    "print('X_test_pca_placed = ', X_test_pca_placed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c =  0.8 kernel =  rbf acc =  0.3020833333333333\n",
      "c =  1 kernel =  rbf acc =  0.3020833333333333\n",
      "c =  1.5 kernel =  rbf acc =  0.3229166666666667\n",
      "c =  10 kernel =  rbf acc =  0.28125\n",
      "c =  0.8 kernel =  sigmoid acc =  0.3020833333333333\n",
      "c =  1 kernel =  sigmoid acc =  0.3020833333333333\n",
      "c =  1.5 kernel =  sigmoid acc =  0.3020833333333333\n",
      "c =  10 kernel =  sigmoid acc =  0.2916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C_list = [0.8,1,1.5,10]\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "  for c in C_list:\n",
    "    #print(c)\n",
    "    clf_svm = svm.SVC(C = c,kernel=kernel,random_state=20)\n",
    "    clf_svm.fit(X_train_pca_placed,Y_train_pca_placed)\n",
    "    y_pred_placed_pca_svm = clf_svm.predict(X_test_pca_placed)\n",
    "    acc = accuracy(Y_test_pca_placed,y_pred_placed_pca_svm)\n",
    "    #c_dict[acc] = [c,kernel]\n",
    "    print(\"c = \",c,\"kernel = \",kernel,\"acc = \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the available data, 960 data points for placed candidates is pretty less. The best way to improve accuracy is by using feature selection, feature transformation, ensemble learning, trying various algorithms. After trying all the approaches, the best model is the one that gives 36% accuracy(SVM) on determing how long it will take for a person to get placed. The only way now to improve accuracy is to collect more data. Also, a regression approach is a better way to find how long it would take for a get a job. For this, instead of mentioning ranges of months, exact duration would be helpful in determining the duration. Better features could be included like whether the resume was reviewed, whether there were previous projects in the field of job applied, whether the candidate prepares before interview, how long do they revise, etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
